{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5cbe6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33fa7c1",
   "metadata": {},
   "source": [
    "Importing and Reading Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a6c3c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b807ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec3a356",
   "metadata": {},
   "source": [
    "Minor Data Preprocessing for Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def get_median(x):\n",
    "    split_list = x.split(' TO ')\n",
    "    float_list = [float(i) for i in split_list]\n",
    "    median = statistics.median(float_list)\n",
    "    return median\n",
    "\n",
    "df['storey_median'] = df['storey_range'].apply(lambda x: get_median(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_df = df[['cbd_dist','min_dist_mrt','floor_area_sqm','lease_remain_years','storey_median','resale_price']]\n",
    "scope_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_df = scope_df.drop_duplicates()\n",
    "scope_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5598b31",
   "metadata": {},
   "source": [
    "Checking and Handling for Skewness in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of columns(continuous variables) for finding skewness\n",
    "col = ['cbd_dist','min_dist_mrt','floor_area_sqm','lease_remain_years','storey_median','resale_price']\n",
    "\n",
    "for i in col:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(data=df, x=i)\n",
    "    plt.title(f'Boxplot of {i}')\n",
    "    plt.xlabel(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a18429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = scope_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae290be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a logarithmic transformation to the required columns only.\n",
    "# One need to apply it and check, in some cases it will handle the skewness, and in other cases it might not have a great\n",
    "                                                                # effect on the data, so no need to apply for that columns\n",
    "\n",
    "df1['floor_area_sqm'] = np.log(df1['floor_area_sqm'])\n",
    "sns.boxplot(x='floor_area_sqm', data=df1)\n",
    "plt.show()\n",
    "\n",
    "df1['storey_median'] = np.log(df1['storey_median'])\n",
    "sns.boxplot(x='storey_median', data=df1)\n",
    "plt.show()\n",
    "\n",
    "df1['resale_price'] = np.log(df1['resale_price'])\n",
    "sns.boxplot(x='resale_price', data=df1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1151c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee8d7a0",
   "metadata": {},
   "source": [
    "Visualization among different columns using Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b00564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corrMatrix = df1.corr()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "sns.heatmap(\n",
    "    corrMatrix,\n",
    "    xticklabels=corrMatrix.columns,\n",
    "    yticklabels=corrMatrix.columns,\n",
    "    cmap='RdBu',\n",
    "    annot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20acb521",
   "metadata": {},
   "source": [
    "Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X=df1[['cbd_dist','min_dist_mrt','floor_area_sqm','lease_remain_years','storey_median']]\n",
    "y=df1['resale_price']\n",
    "\n",
    "# Normalizing the encoded data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddfc5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.DataFrame(X)\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3900aa5b",
   "metadata": {},
   "source": [
    "Splitting the Data for Training and Testing Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f611a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test and train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16165558",
   "metadata": {},
   "source": [
    "Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6957eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "# hyperparameters\n",
    "param_grid = {\n",
    "    'max_depth': [2, 5, 10, 15, 20, 22],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# gridsearchcv\n",
    "grid_search = GridSearchCV(estimator=dtr, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# evalution metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\" \")\n",
    "print('Mean squared error:', mse)\n",
    "print('Mean Absolute Error', mae)\n",
    "print('Root Mean squared error:', rmse)\n",
    "print(\" \")\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13bed5a",
   "metadata": {},
   "source": [
    "Testing Our Trained Model (Decision Tree Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = np.array([[8740, 999, np.log(44), 55, np.log(11)]])\n",
    "new_sample = scaler.transform(new_sample[:, :5])\n",
    "new_pred = best_model.predict(new_sample)[0]\n",
    "np.exp(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7888c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "import pickle\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
